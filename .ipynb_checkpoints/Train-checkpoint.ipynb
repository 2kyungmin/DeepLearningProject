{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114f7714-ceef-4809-acc8-22be7358c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from common.utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "import csv\n",
    "\n",
    "from dataset.gillam import load_data\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "corpus, word_to_id, id_to_word = load_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79962f6-d2fc-4a2e-b78b-07bd813ad7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children num: 540\n",
      "vocab size: 3721\n",
      "0\n",
      "0\n",
      "1\n",
      "max length and index: 1718 467\n"
     ]
    }
   ],
   "source": [
    "print('children num:', len(corpus))\n",
    "print('vocab size:', len(word_to_id))\n",
    "\n",
    "print(corpus[0][-1])\n",
    "print(corpus[100][-1])\n",
    "print(corpus[200][-1])\n",
    "\n",
    "max_index = np.argmax([len(x) for x in corpus])\n",
    "print('max length and index:', len(corpus[max_index]), max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac2499e-5203-4d14-952a-0cd79b35ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(D, 1) / 100).astype('f')\n",
    "        affine_b = np.zeros(1).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio)            \n",
    "        ]\n",
    "        self.clf_layer = TimeAffine(affine_W, affine_b)\n",
    "        self.loss_layer = TimeSigmoidWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "\n",
    "        self.last_T = xs.shape[1]\n",
    "        xs = xs[:,-1,:]\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, label, train_flg=True):\n",
    "        xs = self.predict(xs, train_flg)\n",
    "        score = self.clf_layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(score, label)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)    # (N, 1) or (N,) -> (N, 1)\n",
    "        dout = self.clf_layer.backward(dout)     # (N, 1) -> (N, H)\n",
    "\n",
    "        # (N, H) -> (N, T, H)로 확장 (마지막 time step에만 gradient)\n",
    "        N, H = dout.shape\n",
    "        T = self.last_T\n",
    "        dxs = np.zeros((N, T, H), dtype=dout.dtype)\n",
    "        dxs[:, -1, :] = dout   # h_T에만 gradient 전달\n",
    "\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26d82f-69a7-4c33-8df6-4f253530303d",
   "metadata": {},
   "source": [
    "batch_size = 미니배치 크기  \n",
    "max_epoch = 학습 수행하는 에폭 수  \n",
    "eval_interval = 결과 출력 간격  \n",
    "max_grad = 기울기 최대 노름  \n",
    "time_size = RNN이 한번에 펼쳐서 보는 time step 길이  \n",
    "\n",
    "#### 첫번째 모델  \n",
    "- batch_size = 20  \n",
    "- wordvec_size = 256  \n",
    "- hidden_size = 650  \n",
    "- time_size = 35  \n",
    "- lr = 20.0  \n",
    "- max_epoch = 40  \n",
    "- max_grad = 0.25  \n",
    "- dropout = 0.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d6bdf6-3467-474e-9728-b5b7314af461",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m best_ppl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epoch):\n\u001b[1;32m---> 26\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(corpus, label, max_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, time_size\u001b[38;5;241m=\u001b[39mtime_size, max_grad\u001b[38;5;241m=\u001b[39mmax_grad)\n\u001b[0;32m     28\u001b[0m     model\u001b[38;5;241m.\u001b[39mreset_state()\n\u001b[0;32m     29\u001b[0m     ppl \u001b[38;5;241m=\u001b[39m eval_perplexity(model, corpus_val)\n",
      "File \u001b[1;32mc:\\DeepLearning2\\common\\trainer.py:96\u001b[0m, in \u001b[0;36mRnnlmTrainer.fit\u001b[1;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, xs, ts, max_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, time_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m, max_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m     95\u001b[0m     data_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m corpus: data_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# batch_size: 한 번에 학습할 시계열 샘플 개수\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# time_size: RNN이 한 번에 펼쳐서 보는 time step 길이, BPTT의 길이\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# 한 epoch 동안 몇번의 미니배치를 뽑을 수 있는지 계산\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     max_iters \u001b[38;5;241m=\u001b[39m data_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m (batch_size \u001b[38;5;241m*\u001b[39m time_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.utils import eval_perplexity\n",
    "\n",
    "batch_size = 20\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "wordvec_size = 256\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "dropout = 0.5\n",
    "\n",
    "corpus_val, _, _ = load_data(\"dev\")\n",
    "corpus_test, _, _ = load_data(\"test\")\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "label = np.array([corpus[i][-1] for i in range(len(corpus))])\n",
    "\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(corpus, label, max_epoch=1, batch_size=batch_size, time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06e33b17-4951-4d97-a88c-de9af2449e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204143\n"
     ]
    }
   ],
   "source": [
    "data_size = 0\n",
    "for x in corpus: data_size += len(x)\n",
    "print(data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5270ecd1-5a2a-44ff-87dc-95553df22566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
